% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mcmc_samplers.R
\name{btf_reg}
\alias{btf_reg}
\title{MCMC Sampler for Bayesian Trend Filtering: Regression}
\usage{
btf_reg(y, X = NULL, evol_error = "DHS", D = 2, nsave = 1000,
  nburn = 1000, nskip = 4, mcmc_params = list("mu", "yhat", "beta"),
  computeDIC = TRUE)
}
\arguments{
\item{y}{the \code{T x 1} vector of time series observations}

\item{X}{the \code{T x p} matrix of time series predictors}

\item{evol_error}{the evolution error distribution; must be one of
'DHS' (dynamic horseshoe prior), 'HS' (horseshoe prior), or 'NIG' (normal-inverse-gamma prior)}

\item{D}{degree of differencing (D = 1 or D = 2)}

\item{nsave}{number of MCMC iterations to record}

\item{nburn}{number of MCMC iterations to discard (burin-in)}

\item{nskip}{number of MCMC iterations to skip between saving iterations,
i.e., save every (nskip + 1)th draw}

\item{mcmc_params}{named list of parameters for which we store the MCMC output;
must be one or more of:
\itemize{
\item "mu" (conditional mean)
\item "yhat" (posterior predictive distribution)
\item "beta" (dynamic regression coefficients)
\item "evol_sigma_t2" (evolution error variance)
\item "obs_sigma_t2" (observation error variance)
\item "dhs_phi" (DHS AR(1) coefficient)
\item "dhs_mean" (DHS AR(1) unconditional mean)
}}

\item{computeDIC}{logical; if TRUE, compute the deviance information criterion \code{DIC}
and the effective number of parameters \code{p_d}}
}
\value{
A named list of the \code{nsave} MCMC samples for the parameters named in \code{mcmc_params}
}
\description{
Run the MCMC for Bayesian trend filtering regression with a penalty on
first (D=1) or second (D=2) differences of each dynamic regression coefficient.
The penalty is determined by the prior on the evolution errors, which include:
\itemize{
\item the dynamic horseshoe prior ('DHS');
\item the static horseshoe prior ('HS');
\item the normal-inverse-gamma prior ('NIG').
}
In each case, the evolution error is a scale mixture of Gaussians.
Sampling is accomplished with a (parameter-expanded) Gibbs sampler,
mostly relying on a dynamic linear model representation.
}
\note{
The data \code{y} may contain NAs, which will be treated with a simple imputation scheme
via an additional Gibbs sampling step. In general, rescaling \code{y} to have unit standard
deviation is recommended to avoid numerical issues.
}
\examples{
# Example 1: levelshift and doppler regression
simdata = simRegression(signalNames = c("levelshift", "doppler"), p_0 = 2)
y = simdata$y; X = simdata$X
mcmc_output = btf_reg(y, X)
for(j in 1:ncol(X))
 plot_fitted(rep(0, length(y)),
             mu = colMeans(mcmc_output$beta[,,j]),
             postY = mcmc_output$beta[,,j],
             y_true = simdata$beta_true[,j])

# Example 2: jumpsine and blocks; longer time series, more zeros
simdata = simRegression(signalNames = c("jumpsine", "blocks"), p_0 = 5, T = 500)
y = simdata$y; X = simdata$X
mcmc_output = btf_reg(y, X, nsave = 1000, nskip = 0) # Short MCMC run for a quick example
for(j in 1:ncol(X))
  plot_fitted(rep(0, length(y)),
              mu = colMeans(mcmc_output$beta[,,j]),
              postY = mcmc_output$beta[,,j],
              y_true = simdata$beta_true[,j])

}
